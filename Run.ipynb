{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from data_handler import DataHandler\n",
    "from models import create_grud_model, load_grud_model\n",
    "from nn_utils.callbacks import ModelCheckpointwithBestWeights\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU usage for tensorflow backend\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = .1\n",
    "    config.gpu_options.allow_growth = True\n",
    "    K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: Namespace(batch_size=32, dataset_name='sample', early_stopping_patience=10, epochs=100, hidden_dim=[], label_name='taskname', max_timestamp=172800, max_timesteps=200, model='GRUD', pretrained_model_file=None, recurrent_dim=[64], use_bidirectional_rnn=False, working_path='.')\n"
     ]
    }
   ],
   "source": [
    "# parse arguments\n",
    "## general\n",
    "arg_parser = argparse.ArgumentParser()\n",
    "arg_parser.add_argument('--working_path', default='.')\n",
    "\n",
    "## data\n",
    "arg_parser.add_argument('dataset_name', default='mimic3',\n",
    "                        help='The data files should be saved in [working_path]/data/[dataset_name] directory.')\n",
    "arg_parser.add_argument('label_name', default='mortality')\n",
    "arg_parser.add_argument('--max_timesteps', type=int, default=200, \n",
    "                        help='Time series of at most # time steps are used. Default: 200.')\n",
    "arg_parser.add_argument('--max_timestamp', type=int, default=48*60*60,\n",
    "                        help='Time series of at most # seconds are used. Default: 48 (hours).')\n",
    "\n",
    "## model\n",
    "arg_parser.add_argument('--recurrent_dim', type=lambda x: x and [int(xx) for xx in x.split(',')] or [], default='64')\n",
    "arg_parser.add_argument('--hidden_dim', type=lambda x: x and [int(xx) for xx in x.split(',')] or [], default='64')\n",
    "arg_parser.add_argument('--model', default='GRUD', choices=['GRUD', 'GRUforward', 'GRU0', 'GRUsimple'])\n",
    "arg_parser.add_argument('--use_bidirectional_rnn', default=False)\n",
    "                           \n",
    "## training\n",
    "arg_parser.add_argument('--pretrained_model_file', default=None,\n",
    "                        help='If pre-trained model is provided, training will be skipped.') # e.g., [model_name]_[i_fold].h5\n",
    "arg_parser.add_argument('--epochs', type=int, default=100)\n",
    "arg_parser.add_argument('--early_stopping_patience', type=int, default=10)\n",
    "arg_parser.add_argument('--batch_size', type=int, default=32)\n",
    "\n",
    "\n",
    "## set the actual arguments if running in notebook\n",
    "if not (__name__ == '__main__' and '__file__' in globals()):\n",
    "    ARGS = arg_parser.parse_args([\n",
    "        'sample',\n",
    "        'taskname',\n",
    "        '--model', 'GRUD',\n",
    "        '--hidden_dim', '',\n",
    "        '--epochs', '100'\n",
    "    ])\n",
    "else:\n",
    "    ARGS = arg_parser.parse_args()\n",
    "\n",
    "print('Arguments:', ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "dataset = DataHandler(\n",
    "    data_path=os.path.join(ARGS.working_path, 'data', ARGS.dataset_name), \n",
    "    label_name=ARGS.label_name,\n",
    "    max_steps=ARGS.max_timesteps,\n",
    "    max_timestamp=ARGS.max_timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20230505_184652_394531\n",
      "0-th fold...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 7)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 7)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "external_masking_1 (ExternalMas (None, None, 7)      0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 7)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "external_masking_2 (ExternalMas (None, None, 1)      0           input_3[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "grud_1 (GRUD)                   (None, 64)           15694       external_masking_1[0][0]         \n",
      "                                                                 masking_1[0][0]                  \n",
      "                                                                 external_masking_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           grud_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            195         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,889\n",
      "Trainable params: 15,889\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/Zheng/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 596ms/step - loss: 0.8579 - val_loss: 0.8481\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8237 - val_loss: 0.8020\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7985 - val_loss: 0.7574\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7897 - val_loss: 0.7172\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6976 - val_loss: 0.6815\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6966 - val_loss: 0.6495\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6806 - val_loss: 0.6210\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6616 - val_loss: 0.5963\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6552 - val_loss: 0.5750\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6425 - val_loss: 0.5566\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6218 - val_loss: 0.5410\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6347 - val_loss: 0.5281\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6054 - val_loss: 0.5174\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5765 - val_loss: 0.5088\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6173 - val_loss: 0.5017\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6181 - val_loss: 0.4957\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6037 - val_loss: 0.4908\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5849 - val_loss: 0.4871\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6027 - val_loss: 0.4843\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6076 - val_loss: 0.4819\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5763 - val_loss: 0.4800\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6027 - val_loss: 0.4786\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5668 - val_loss: 0.4774\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5518 - val_loss: 0.4762\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5565 - val_loss: 0.4755\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5976 - val_loss: 0.4745\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5932 - val_loss: 0.4735\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5489 - val_loss: 0.4725\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5481 - val_loss: 0.4711\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5525 - val_loss: 0.4697\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5757 - val_loss: 0.4684\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5671 - val_loss: 0.4670\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5580 - val_loss: 0.4656\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5427 - val_loss: 0.4647\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5345 - val_loss: 0.4633\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4992 - val_loss: 0.4618\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5530 - val_loss: 0.4604\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5032 - val_loss: 0.4592\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5412 - val_loss: 0.4577\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5225 - val_loss: 0.4569\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5141 - val_loss: 0.4552\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5346 - val_loss: 0.4538\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5082 - val_loss: 0.4516\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5010 - val_loss: 0.4495\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5191 - val_loss: 0.4473\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4900 - val_loss: 0.4451\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4761 - val_loss: 0.4427\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5003 - val_loss: 0.4403\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5174 - val_loss: 0.4375\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5108 - val_loss: 0.4353\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4577 - val_loss: 0.4329\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4872 - val_loss: 0.4308\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4718 - val_loss: 0.4285\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5026 - val_loss: 0.4262\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4908 - val_loss: 0.4240\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4705 - val_loss: 0.4217\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4692 - val_loss: 0.4200\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4847 - val_loss: 0.4181\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4644 - val_loss: 0.4162\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4771 - val_loss: 0.4141\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4755 - val_loss: 0.4122\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4309 - val_loss: 0.4104\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4545 - val_loss: 0.4089\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4638 - val_loss: 0.4071\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4592 - val_loss: 0.4054\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4523 - val_loss: 0.4037\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4414 - val_loss: 0.4023\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4487 - val_loss: 0.4012\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4357 - val_loss: 0.4001\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4365 - val_loss: 0.3990\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4725 - val_loss: 0.3981\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4313 - val_loss: 0.3975\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4705 - val_loss: 0.3966\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4238 - val_loss: 0.3956\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4339 - val_loss: 0.3948\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4413 - val_loss: 0.3941\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4278 - val_loss: 0.3929\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4125 - val_loss: 0.3914\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4423 - val_loss: 0.3900\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4454 - val_loss: 0.3883\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4141 - val_loss: 0.3865\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4137 - val_loss: 0.3848\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4426 - val_loss: 0.3832\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4273 - val_loss: 0.3814\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4161 - val_loss: 0.3796\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4314 - val_loss: 0.3774\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4281 - val_loss: 0.3755\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4139 - val_loss: 0.3738\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4471 - val_loss: 0.3723\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4311 - val_loss: 0.3712\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4203 - val_loss: 0.3700\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4453 - val_loss: 0.3692\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4170 - val_loss: 0.3681\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4277 - val_loss: 0.3675\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4225 - val_loss: 0.3671\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3999 - val_loss: 0.3668\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4224 - val_loss: 0.3668\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4236 - val_loss: 0.3669\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4143 - val_loss: 0.3674\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4116 - val_loss: 0.3682\n",
      "..........................AUC score of this fold: [0.8884166666666666, 0.8310439560439561, 0.8583453583453583]\n",
      "1-th fold...\n",
      ".Epoch 1/100\n",
      "2/2 [==============================] - 1s 631ms/step - loss: 0.7346 - val_loss: 0.6724\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7062 - val_loss: 0.6563\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6914 - val_loss: 0.6438\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6531 - val_loss: 0.6339\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6484 - val_loss: 0.6264\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6230 - val_loss: 0.6210\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6231 - val_loss: 0.6173\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6095 - val_loss: 0.6154\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5652 - val_loss: 0.6146\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5683 - val_loss: 0.6143\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6025 - val_loss: 0.6144\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5636 - val_loss: 0.6146\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5711 - val_loss: 0.6147\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6115 - val_loss: 0.6143\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5479 - val_loss: 0.6131\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5644 - val_loss: 0.6115\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5544 - val_loss: 0.6090\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5346 - val_loss: 0.6066\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5398 - val_loss: 0.6038\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5311 - val_loss: 0.5998\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4978 - val_loss: 0.5962\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5396 - val_loss: 0.5918\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5469 - val_loss: 0.5869\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5433 - val_loss: 0.5823\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4958 - val_loss: 0.5771\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5340 - val_loss: 0.5716\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5131 - val_loss: 0.5660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5100 - val_loss: 0.5604\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5064 - val_loss: 0.5545\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4888 - val_loss: 0.5491\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5221 - val_loss: 0.5435\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4784 - val_loss: 0.5379\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5005 - val_loss: 0.5327\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4929 - val_loss: 0.5270\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4893 - val_loss: 0.5218\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5035 - val_loss: 0.5170\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4742 - val_loss: 0.5125\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4749 - val_loss: 0.5083\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4852 - val_loss: 0.5044\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4795 - val_loss: 0.5009\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4721 - val_loss: 0.4977\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4660 - val_loss: 0.4944\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4965 - val_loss: 0.4912\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4881 - val_loss: 0.4882\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4937 - val_loss: 0.4853\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4663 - val_loss: 0.4825\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4659 - val_loss: 0.4796\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4659 - val_loss: 0.4769\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4881 - val_loss: 0.4744\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4795 - val_loss: 0.4717\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4704 - val_loss: 0.4693\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4555 - val_loss: 0.4669\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4429 - val_loss: 0.4644\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4339 - val_loss: 0.4622\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4371 - val_loss: 0.4602\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4586 - val_loss: 0.4581\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4407 - val_loss: 0.4562\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4312 - val_loss: 0.4543\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4110 - val_loss: 0.4523\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4122 - val_loss: 0.4504\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4292 - val_loss: 0.4487\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4160 - val_loss: 0.4471\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4088 - val_loss: 0.4457\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4028 - val_loss: 0.4445\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4345 - val_loss: 0.4434\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4231 - val_loss: 0.4423\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4174 - val_loss: 0.4412\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4179 - val_loss: 0.4399\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4096 - val_loss: 0.4387\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4171 - val_loss: 0.4370\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3979 - val_loss: 0.4355\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4053 - val_loss: 0.4338\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3984 - val_loss: 0.4326\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3915 - val_loss: 0.4314\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4061 - val_loss: 0.4304\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4159 - val_loss: 0.4294\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3887 - val_loss: 0.4284\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3975 - val_loss: 0.4274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3881 - val_loss: 0.4262\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4096 - val_loss: 0.4250\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4299 - val_loss: 0.4239\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3977 - val_loss: 0.4228\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4086 - val_loss: 0.4219\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4063 - val_loss: 0.4211\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4154 - val_loss: 0.4204\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4181 - val_loss: 0.4200\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4045 - val_loss: 0.4194\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3894 - val_loss: 0.4186\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4162 - val_loss: 0.4183\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3977 - val_loss: 0.4181\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3742 - val_loss: 0.4179\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3789 - val_loss: 0.4174\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3855 - val_loss: 0.4168\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3983 - val_loss: 0.4163\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3915 - val_loss: 0.4157\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3587 - val_loss: 0.4151\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3808 - val_loss: 0.4143\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3532 - val_loss: 0.4136\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3865 - val_loss: 0.4129\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3825 - val_loss: 0.4122\n",
      "..............................AUC score of this fold: [0.8989487467265245, 0.6987179487179488, 0.7529189560439561]\n",
      "2-th fold...\n",
      ".Epoch 1/100\n",
      "2/2 [==============================] - 1s 608ms/step - loss: 0.8283 - val_loss: 0.8338\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7736 - val_loss: 0.8077\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7389 - val_loss: 0.7851\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6779 - val_loss: 0.7647\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6650 - val_loss: 0.7470\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6679 - val_loss: 0.7325\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6183 - val_loss: 0.7200\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5867 - val_loss: 0.7095\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5842 - val_loss: 0.7010\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5733 - val_loss: 0.6941\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5302 - val_loss: 0.6892\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5392 - val_loss: 0.6847\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5339 - val_loss: 0.6818\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5544 - val_loss: 0.6792\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5172 - val_loss: 0.6767\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4984 - val_loss: 0.6752\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5215 - val_loss: 0.6740\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5250 - val_loss: 0.6720\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5094 - val_loss: 0.6701\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5259 - val_loss: 0.6691\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5129 - val_loss: 0.6678\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5117 - val_loss: 0.6657\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4950 - val_loss: 0.6633\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4737 - val_loss: 0.6604\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5017 - val_loss: 0.6579\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4753 - val_loss: 0.6552\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4837 - val_loss: 0.6527\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4910 - val_loss: 0.6493\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4751 - val_loss: 0.6455\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4784 - val_loss: 0.6417\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4824 - val_loss: 0.6379\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4789 - val_loss: 0.6330\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4794 - val_loss: 0.6284\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4452 - val_loss: 0.6231\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4831 - val_loss: 0.6182\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4394 - val_loss: 0.6132\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4253 - val_loss: 0.6083\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4721 - val_loss: 0.6039\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4438 - val_loss: 0.5996\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4615 - val_loss: 0.5959\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4658 - val_loss: 0.5927\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4552 - val_loss: 0.5897\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4499 - val_loss: 0.5865\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4309 - val_loss: 0.5835\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4312 - val_loss: 0.5806\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4251 - val_loss: 0.5776\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4343 - val_loss: 0.5743\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4684 - val_loss: 0.5709\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4303 - val_loss: 0.5674\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4074 - val_loss: 0.5634\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4523 - val_loss: 0.5602\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4326 - val_loss: 0.5570\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4224 - val_loss: 0.5542\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4092 - val_loss: 0.5513\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4341 - val_loss: 0.5488\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3944 - val_loss: 0.5463\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3885 - val_loss: 0.5443\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4097 - val_loss: 0.5425\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4005 - val_loss: 0.5403\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3893 - val_loss: 0.5387\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4071 - val_loss: 0.5363\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3937 - val_loss: 0.5340\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3939 - val_loss: 0.5321\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3871 - val_loss: 0.5303\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4034 - val_loss: 0.5291\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3986 - val_loss: 0.5273\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4161 - val_loss: 0.5258\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3899 - val_loss: 0.5242\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4071 - val_loss: 0.5221\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3794 - val_loss: 0.5207\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3934 - val_loss: 0.5200\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4004 - val_loss: 0.5184\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3797 - val_loss: 0.5159\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3792 - val_loss: 0.5145\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3474 - val_loss: 0.5129\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3657 - val_loss: 0.5108\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3539 - val_loss: 0.5092\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3765 - val_loss: 0.5076\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3663 - val_loss: 0.5068\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3563 - val_loss: 0.5058\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3632 - val_loss: 0.5047\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3730 - val_loss: 0.5039\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3675 - val_loss: 0.5032\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3538 - val_loss: 0.5023\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3651 - val_loss: 0.5014\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3576 - val_loss: 0.5003\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3359 - val_loss: 0.4994\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3537 - val_loss: 0.4985\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3291 - val_loss: 0.4975\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3234 - val_loss: 0.4964\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3469 - val_loss: 0.4958\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3344 - val_loss: 0.4948\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3264 - val_loss: 0.4940\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3641 - val_loss: 0.4930\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3434 - val_loss: 0.4911\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3364 - val_loss: 0.4898\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3362 - val_loss: 0.4891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3228 - val_loss: 0.4885\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3179 - val_loss: 0.4880\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3350 - val_loss: 0.4874\n",
      "..............................AUC score of this fold: [0.8761281799476244, 0.7290140415140415, 0.7393162393162394]\n",
      "3-th fold...\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 639ms/step - loss: 0.8968 - val_loss: 0.8361\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8781 - val_loss: 0.7956\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7849 - val_loss: 0.7587\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7723 - val_loss: 0.7249\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7496 - val_loss: 0.6939\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7115 - val_loss: 0.6668\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6794 - val_loss: 0.6426\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6455 - val_loss: 0.6215\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6612 - val_loss: 0.6036\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6374 - val_loss: 0.5889\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5967 - val_loss: 0.5761\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5941 - val_loss: 0.5655\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6123 - val_loss: 0.5568\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5952 - val_loss: 0.5494\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5597 - val_loss: 0.5432\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5833 - val_loss: 0.5381\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5533 - val_loss: 0.5336\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5712 - val_loss: 0.5298\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5566 - val_loss: 0.5268\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5663 - val_loss: 0.5242\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5267 - val_loss: 0.5214\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5352 - val_loss: 0.5186\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5237 - val_loss: 0.5157\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5291 - val_loss: 0.5131\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5022 - val_loss: 0.5108\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5362 - val_loss: 0.5083\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5236 - val_loss: 0.5061\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5261 - val_loss: 0.5032\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5136 - val_loss: 0.5007\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4997 - val_loss: 0.4980\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5120 - val_loss: 0.4953\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5089 - val_loss: 0.4926\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5081 - val_loss: 0.4900\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4969 - val_loss: 0.4873\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5133 - val_loss: 0.4848\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4815 - val_loss: 0.4820\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4925 - val_loss: 0.4792\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4889 - val_loss: 0.4766\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4641 - val_loss: 0.4744\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4638 - val_loss: 0.4721\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4570 - val_loss: 0.4701\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4763 - val_loss: 0.4678\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4699 - val_loss: 0.4660\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4591 - val_loss: 0.4645\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4579 - val_loss: 0.4629\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4509 - val_loss: 0.4611\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4635 - val_loss: 0.4592\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4709 - val_loss: 0.4575\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4618 - val_loss: 0.4557\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4313 - val_loss: 0.4538\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4538 - val_loss: 0.4520\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4051 - val_loss: 0.4499\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4202 - val_loss: 0.4482\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4451 - val_loss: 0.4463\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4324 - val_loss: 0.4446\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4430 - val_loss: 0.4432\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4184 - val_loss: 0.4418\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4113 - val_loss: 0.4403\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4069 - val_loss: 0.4389\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4427 - val_loss: 0.4377\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4151 - val_loss: 0.4366\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4052 - val_loss: 0.4353\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4238 - val_loss: 0.4341\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3922 - val_loss: 0.4327\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4001 - val_loss: 0.4315\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4184 - val_loss: 0.4304\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4261 - val_loss: 0.4295\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3962 - val_loss: 0.4284\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3919 - val_loss: 0.4272\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4056 - val_loss: 0.4262\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3782 - val_loss: 0.4253\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4062 - val_loss: 0.4245\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4032 - val_loss: 0.4237\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3847 - val_loss: 0.4228\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3973 - val_loss: 0.4223\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3977 - val_loss: 0.4217\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4051 - val_loss: 0.4210\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3988 - val_loss: 0.4198\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4043 - val_loss: 0.4187\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4030 - val_loss: 0.4172\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3815 - val_loss: 0.4157\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3623 - val_loss: 0.4146\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3979 - val_loss: 0.4136\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3802 - val_loss: 0.4125\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3863 - val_loss: 0.4117\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3718 - val_loss: 0.4108\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3860 - val_loss: 0.4098\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3691 - val_loss: 0.4093\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3960 - val_loss: 0.4087\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3652 - val_loss: 0.4084\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3679 - val_loss: 0.4082\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3777 - val_loss: 0.4081\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3825 - val_loss: 0.4077\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3647 - val_loss: 0.4073\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3679 - val_loss: 0.4066\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3554 - val_loss: 0.4060\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3921 - val_loss: 0.4048\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3816 - val_loss: 0.4035\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3564 - val_loss: 0.4024\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3578 - val_loss: 0.4012\n",
      "...............................AUC score of this fold: [0.9136755332407507, 0.7151274651274652, 0.8125381562881563]\n",
      "4-th fold...\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 614ms/step - loss: 0.8199 - val_loss: 0.8002\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7597 - val_loss: 0.7629\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.7487 - val_loss: 0.7300\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7452 - val_loss: 0.6997\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7013 - val_loss: 0.6731\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6860 - val_loss: 0.6496\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6881 - val_loss: 0.6290\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6243 - val_loss: 0.6112\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6337 - val_loss: 0.5960\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6309 - val_loss: 0.5831\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6038 - val_loss: 0.5724\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5948 - val_loss: 0.5635\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6254 - val_loss: 0.5562\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5895 - val_loss: 0.5495\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5775 - val_loss: 0.5440\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5717 - val_loss: 0.5389\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5894 - val_loss: 0.5348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5766 - val_loss: 0.5311\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5797 - val_loss: 0.5273\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5793 - val_loss: 0.5239\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5595 - val_loss: 0.5203\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5321 - val_loss: 0.5168\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5752 - val_loss: 0.5133\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5618 - val_loss: 0.5099\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5363 - val_loss: 0.5064\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5506 - val_loss: 0.5031\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5366 - val_loss: 0.4996\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5540 - val_loss: 0.4965\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5761 - val_loss: 0.4933\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5060 - val_loss: 0.4902\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5588 - val_loss: 0.4874\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5163 - val_loss: 0.4843\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5115 - val_loss: 0.4815\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4992 - val_loss: 0.4789\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5159 - val_loss: 0.4760\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5234 - val_loss: 0.4732\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4870 - val_loss: 0.4705\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5027 - val_loss: 0.4677\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5086 - val_loss: 0.4648\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4997 - val_loss: 0.4619\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4786 - val_loss: 0.4589\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4924 - val_loss: 0.4557\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5031 - val_loss: 0.4529\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4877 - val_loss: 0.4502\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4887 - val_loss: 0.4477\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4757 - val_loss: 0.4452\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4815 - val_loss: 0.4425\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4566 - val_loss: 0.4400\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4752 - val_loss: 0.4374\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4723 - val_loss: 0.4349\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4889 - val_loss: 0.4323\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4545 - val_loss: 0.4296\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4692 - val_loss: 0.4269\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5009 - val_loss: 0.4245\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4940 - val_loss: 0.4219\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4456 - val_loss: 0.4196\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4738 - val_loss: 0.4174\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4260 - val_loss: 0.4151\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4659 - val_loss: 0.4129\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4566 - val_loss: 0.4106\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4293 - val_loss: 0.4087\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4560 - val_loss: 0.4068\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4473 - val_loss: 0.4050\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4611 - val_loss: 0.4033\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4615 - val_loss: 0.4017\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4341 - val_loss: 0.3999\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4318 - val_loss: 0.3981\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4564 - val_loss: 0.3962\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4533 - val_loss: 0.3943\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4240 - val_loss: 0.3923\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4279 - val_loss: 0.3903\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4070 - val_loss: 0.3884\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4209 - val_loss: 0.3867\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4318 - val_loss: 0.3849\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4450 - val_loss: 0.3834\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4627 - val_loss: 0.3820\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4312 - val_loss: 0.3806\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4290 - val_loss: 0.3788\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4227 - val_loss: 0.3771\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4314 - val_loss: 0.3755\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4160 - val_loss: 0.3739\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4109 - val_loss: 0.3721\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4029 - val_loss: 0.3705\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4185 - val_loss: 0.3691\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4163 - val_loss: 0.3680\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4167 - val_loss: 0.3671\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4258 - val_loss: 0.3660\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4408 - val_loss: 0.3647\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4209 - val_loss: 0.3634\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4070 - val_loss: 0.3621\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3995 - val_loss: 0.3610\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4492 - val_loss: 0.3598\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4143 - val_loss: 0.3587\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4322 - val_loss: 0.3577\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4293 - val_loss: 0.3568\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4302 - val_loss: 0.3559\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4143 - val_loss: 0.3548\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4039 - val_loss: 0.3538\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4108 - val_loss: 0.3528\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4210 - val_loss: 0.3520\n",
      "...............................AUC score of this fold: [0.8559557726224393, 0.8742183742183741, 0.731000481000481]\n",
      "Finished! ====================\n",
      "Mean AUC score: [0.88662498 0.76962436 0.77882384]; Std AUC score: [0.01968553 0.06979843 0.04894755]\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross-validation\n",
    "pred_y_list_all = []\n",
    "auc_score_list_all = []\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "print('Timestamp: {}'.format(timestamp))\n",
    "\n",
    "for i_fold in range(dataset.folds):\n",
    "    print('{}-th fold...'.format(i_fold))\n",
    "\n",
    "    # Load or train the model.\n",
    "    if ARGS.pretrained_model_file is not None:\n",
    "        model = load_grud_model(os.path.join(ARGS.working_path, \n",
    "                                             ARGS.pretrained_model_file.format(i_fold=i_fold)))\n",
    "    else:\n",
    "        model = create_grud_model(input_dim=dataset.input_dim,\n",
    "                                  output_dim=dataset.output_dim,\n",
    "                                  output_activation=dataset.output_activation,\n",
    "                                  recurrent_dim=ARGS.recurrent_dim,\n",
    "                                  hidden_dim=ARGS.hidden_dim,\n",
    "                                  predefined_model=ARGS.model,\n",
    "                                  use_bidirectional_rnn=ARGS.use_bidirectional_rnn\n",
    "                                 )\n",
    "        if i_fold == 0:\n",
    "            model.summary()\n",
    "        model.compile(optimizer='adam', loss=dataset.loss_function)\n",
    "        model.fit_generator(\n",
    "            generator=dataset.training_generator(i_fold, batch_size=ARGS.batch_size),\n",
    "            steps_per_epoch=dataset.training_steps(i_fold, batch_size=ARGS.batch_size),\n",
    "            epochs=ARGS.epochs,\n",
    "            verbose=1,\n",
    "            validation_data=dataset.validation_generator(i_fold, batch_size=ARGS.batch_size),\n",
    "            validation_steps=dataset.validation_steps(i_fold, batch_size=ARGS.batch_size),\n",
    "            callbacks=[\n",
    "                EarlyStopping(patience=ARGS.early_stopping_patience),\n",
    "                ModelCheckpointwithBestWeights(\n",
    "                    file_dir=os.path.join(ARGS.working_path, 'model', timestamp + '_' + str(i_fold))\n",
    "                ),\n",
    "                TensorBoard(\n",
    "                    log_dir=os.path.join(ARGS.working_path, 'tb_logs', timestamp + '_' + str(i_fold))\n",
    "                )\n",
    "            ]\n",
    "            )\n",
    "        model.save(os.path.join(ARGS.working_path, 'model', \n",
    "                                timestamp + '_' + str(i_fold), 'model.h5'))\n",
    "\n",
    "    # Evaluate the model\n",
    "    true_y_list = [\n",
    "        dataset.training_y(i_fold), dataset.validation_y(i_fold), dataset.testing_y(i_fold)\n",
    "    ]\n",
    "    pred_y_list = [\n",
    "        model.predict_generator(dataset.training_generator_x(i_fold, batch_size=ARGS.batch_size),\n",
    "                                steps=dataset.training_steps(i_fold, batch_size=ARGS.batch_size)),\n",
    "        model.predict_generator(dataset.validation_generator_x(i_fold, batch_size=ARGS.batch_size),\n",
    "                                steps=dataset.validation_steps(i_fold, batch_size=ARGS.batch_size)),\n",
    "        model.predict_generator(dataset.testing_generator_x(i_fold, batch_size=ARGS.batch_size),\n",
    "                                steps=dataset.testing_steps(i_fold, batch_size=ARGS.batch_size)),\n",
    "    ]\n",
    "    auc_score_list = [roc_auc_score(ty, py) for ty, py in zip(true_y_list, pred_y_list)] # [3, n_task]\n",
    "    print('AUC score of this fold: {}'.format(auc_score_list))\n",
    "    pred_y_list_all.append(pred_y_list)\n",
    "    auc_score_list_all.append(auc_score_list)\n",
    "\n",
    "print('Finished!', '='*20)\n",
    "auc_score_list_all = np.stack(auc_score_list_all, axis=0)\n",
    "print('Mean AUC score: {}; Std AUC score: {}'.format(\n",
    "    np.mean(auc_score_list_all, axis=0),\n",
    "    np.std(auc_score_list_all, axis=0)))\n",
    "\n",
    "result_path = os.path.join(ARGS.working_path, 'results', timestamp)\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "np.savez_compressed(os.path.join(result_path, 'predictions.npz'),\n",
    "                    pred_y_list_all=pred_y_list_all)\n",
    "np.savez_compressed(os.path.join(result_path, 'auroc_score.npz'),\n",
    "                    auc_score_list_all=auc_score_list_all)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
